extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  http_forwarder:
    ingress:
      endpoint: 0.0.0.0:6060
    egress:
      # TODO: Ensure this is set properly
      endpoint: "https://api.${SPLUNK_REALM}.signalfx.com"
  zpages:
receivers:
  filelog:
    include:
      - /var/lib/docker/containers/*/*-json.log
    encoding: utf-8
    fingerprint_size: 1kb
    force_flush_period: "0"
    include_file_name: false
    include_file_path: true
    max_concurrent_files: 1024
    max_log_size: 1MiB
    operators:
      - id: parser-docker
        timestamp:
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          parse_from: attributes.time
        type: json_parser
      - id: extract_metadata_from_docker_tag
        parse_from: attributes.attrs.tag
        regex: ^(?P<name>[^\|]+)\|(?P<image_name>[^\|]+)\|(?P<id>[^$]+)$
        type: regex_parser
        if: 'attributes?.attrs?.tag != nil'
      - from: attributes.name
        to: resource["com.splunk.sourcetype"]
        type: copy
        if: 'attributes?.name != nil'
      - from: attributes.name
        to: resource["docker.container.name"]
        type: move
        if: 'attributes?.name != nil'
      - from: attributes.image_name
        to: resource["docker.image.name"]
        type: move
        if: 'attributes?.image_name != nil'
      - from: attributes.id
        to: resource["docker.container.id"]
        type: move
        if: 'attributes?.id != nil'
      - from: attributes.stream
        to: resource["log.io.stream"]
        type: move
      - field: attributes.attrs.tag
        type: remove
        if: 'attributes?.attrs?.tag != nil'
      - from: attributes.log
        to: body
        type: move
    poll_interval: 200ms
    start_at: beginning

  hostmetrics:
    collection_interval: 10s
    scrapers:
      cpu:
      disk:
      filesystem:
      memory:
      network:
      # System load average metrics https://en.wikipedia.org/wiki/Load_(computing)
      load:
      # Paging/Swap space utilization and I/O metrics
      paging:
      # Aggregated system process count metrics
      processes:
      # System processes metrics, disabled by default
      # process:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  signalfx:
    endpoint: 0.0.0.0:9943
  # This section is used to collect OpenTelemetry metrics
  # Even if just a SignalFx APM customer, these metrics are included
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['localhost:8888']
              # If you want to use the environment filter
              # In the SignalFx dashboard
              #labels:
              #environment: demo
          metric_relabel_configs:
            - source_labels: [ __name__ ]
              regex: '.*grpc_io.*'
              action: drop
  # Enable Zipkin to support Istio Mixer Adapter
  # https://github.com/signalfx/signalfx-istio-adapter
  zipkin:
    endpoint: 0.0.0.0:9411
  redis:
    endpoint: "valkey-cart:6379"
    username: "valkey"
    collection_interval: 10s

processors:
  batch:

  # Enabling the memory_limiter is strongly recommended for every pipeline.
  # Configuration is based on the amount of memory allocated to the collector.
  # For more information about memory limiter, see
  # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiter/README.md
  memory_limiter:
    check_interval: 2s
    limit_mib: ${SPLUNK_MEMORY_LIMIT_MIB}

  resource/add_environment:
    attributes:
      - action: insert
        value: test
        key: deployment.environment

  resourcedetection:
    detectors:
      - env
      - system
    timeout: 10s
    override: true

exporters:
  # Traces
  otlphttp:
    traces_endpoint: "https://ingest.${SPLUNK_REALM}.signalfx.com/v2/trace/otlp"
    headers:
      "X-SF-Token": "${SPLUNK_ACCESS_TOKEN}"
  # Metrics
  signalfx:
    # TODO: Ensure this is set properly
    access_token: "${SPLUNK_ACCESS_TOKEN}"
    # TODO: Ensure this is set properly
    realm: "${SPLUNK_REALM}"
    sync_host_metadata: true
  # Logs (can also be used to send traces)
  splunk_hec:
    token: "${SPLUNK_HEC_TOKEN}"
    endpoint: "${SPLUNK_HEC_URL}/services/collector"
    source: "otel"
    sourcetype: "otel"
    index: "astronomyshop"
    profiling_data_enabled: false
    tls:
      insecure_skip_verify: false

service:
  extensions: [health_check, http_forwarder, zpages]
  #  telemetry:
  #    logs:
  #      level: "debug"

  pipelines:
    traces:
      receivers: [otlp, zipkin]
      processors: [memory_limiter, batch, resourcedetection, resource/add_environment]
      exporters: [ otlphttp, signalfx ]
    metrics:
      receivers: [otlp, signalfx, prometheus, hostmetrics]
      processors: [memory_limiter, batch, resourcedetection, resource/add_environment]
      exporters: [signalfx]
    logs:
      receivers: [otlp, signalfx, filelog]
      processors: [memory_limiter, batch, resourcedetection, resource/add_environment]
      exporters: [splunk_hec]
    metrics/additional-receivers:
      exporters:
        - signalfx
      processors:
        - memory_limiter
        - batch
        - resourcedetection
        - resource/add_environment
      receivers:
        - redis
